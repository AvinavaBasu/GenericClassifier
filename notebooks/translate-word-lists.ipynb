{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook translates English terms in word lists into various big languages (French, German, etc.).\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Pool all words from various word lists together\n",
    "2. Run the words through Google translate and save the translations to one file per language\n",
    "3. Examine those files manually\n",
    "4. Go through word lists and apply translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /anaconda2/envs/generic-classifier/lib/python3.6/site-packages (2.22.0)\n",
      "Requirement already satisfied: google-cloud-translate in /anaconda2/envs/generic-classifier/lib/python3.6/site-packages (2.0.0)\n",
      "Requirement already satisfied: tqdm in /anaconda2/envs/generic-classifier/lib/python3.6/site-packages (4.38.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /anaconda2/envs/generic-classifier/lib/python3.6/site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda2/envs/generic-classifier/lib/python3.6/site-packages (from requests) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /anaconda2/envs/generic-classifier/lib/python3.6/site-packages (from requests) (1.25.7)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /anaconda2/envs/generic-classifier/lib/python3.6/site-packages (from requests) (2.8)\n",
      "Requirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.14.0 in /anaconda2/envs/generic-classifier/lib/python3.6/site-packages (from google-cloud-translate) (1.14.3)\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /anaconda2/envs/generic-classifier/lib/python3.6/site-packages (from google-cloud-translate) (1.0.3)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /anaconda2/envs/generic-classifier/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-translate) (3.10.0)\n",
      "Requirement already satisfied: setuptools>=34.0.0 in /anaconda2/envs/generic-classifier/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-translate) (41.6.0.post20191030)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /anaconda2/envs/generic-classifier/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-translate) (1.6.0)\n",
      "Requirement already satisfied: pytz in /anaconda2/envs/generic-classifier/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-translate) (2019.3)\n",
      "Requirement already satisfied: six>=1.10.0 in /anaconda2/envs/generic-classifier/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-translate) (1.12.0)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=0.4.0 in /anaconda2/envs/generic-classifier/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-translate) (1.7.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.8.2; extra == \"grpc\" in /anaconda2/envs/generic-classifier/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-translate) (1.25.0)\n",
      "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /anaconda2/envs/generic-classifier/lib/python3.6/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-translate) (3.1.1)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /anaconda2/envs/generic-classifier/lib/python3.6/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-translate) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /anaconda2/envs/generic-classifier/lib/python3.6/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-translate) (0.2.7)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /anaconda2/envs/generic-classifier/lib/python3.6/site-packages (from rsa<4.1,>=3.1.4->google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-translate) (0.4.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests google-cloud-translate tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import time\n",
    "from google.cloud import translate_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist_paths = glob('dicts/*.txt')\n",
    "wordlist_paths = [p for p in wordlist_paths \n",
    "                  if 'whitelist' not in p.lower() and 'blacklist' not in p.lower()\n",
    "                  and 'allLocDict' not in p and 'sw_dict' not in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for p in wordlist_paths:\n",
    "    with open(p) as f:\n",
    "        files.append(f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(120, 'dicts/typesDict.txt'),\n",
       " (1705, 'dicts/subjectsDict.txt'),\n",
       " (343, 'dicts/subjectModifiersDict.txt'),\n",
       " (24, 'dicts/companyTypes.txt'),\n",
       " (23, 'dicts/commonSubjectsDict.txt'),\n",
       " (9, 'dicts/orgModifiersDict.txt'),\n",
       " (79, 'dicts/wordEndingsDict.txt'),\n",
       " (15521, 'dicts/subjectsDict-new.txt'),\n",
       " (30, 'dicts/univKeywords.txt'),\n",
       " (9, 'dicts/companySuffixes.txt'),\n",
       " (5, 'dicts/connectorsDict.txt'),\n",
       " (543, 'dicts/companyNames.txt')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(len(lines), path) for lines, path in zip(files, wordlist_paths)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = list(set(line.strip() for s in files for line in s))\n",
    "phrases = [p for p in phrases if p] # remove empty string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17800"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eye-balling some words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Choc', 'Surgeon', 'Weld', 'Neuromicrobiology', 'Biotechn',\n",
       "       'Adjudic', 'Opthamology', 'first-fuel-software', 'ANFBEREIT-TECH',\n",
       "       'gastroenterology peidiatraiceach', 'turn',\n",
       "       'Community Health Sciences', 'Nuerosci', 'Pneumonology',\n",
       "       'Carcinog', 'neuroscienze', 'Ultim', 'diMatematica',\n",
       "       'Oftalmologiga', 'TRUBOPPROVODN'], dtype='<U57')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(phrases, size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dicts/subjectsDict-new.txt:Verhaltensmgiger\r\n"
     ]
    }
   ],
   "source": [
    "!grep Verhaltensmgiger dicts/*.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dicts/subjectsDict-new.txt:KELLOQ\r\n"
     ]
    }
   ],
   "source": [
    "!grep KELLOQ dicts/*.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dicts/subjectsDict-new.txt:Gemol\r\n"
     ]
    }
   ],
   "source": [
    "!grep Gemol dicts/*.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up and checking Google Translate API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(\"../google-api-key.json\"), \"You might want to point to your Google API key and provide a project ID\"\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"../google-api-key.json\"\n",
    "project = 'projects/4995602461'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_languages = [\"fr\", \"es\", \"pt\", \"ca\", 'nl', 'de', 'fi', 'da', 'no', 'tr', 'hu', 'pl', 'el']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = translate_v3.TranslationServiceClient()\n",
    "supported_languages = client.get_supported_languages(project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "supported_languages = set(lang.language_code for lang in supported_languages.languages)\n",
    "assert all(l in supported_languages for l in target_languages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate all English phrases into each of chosen languages\n",
    "\n",
    "To run the code below, you'll need to provide an API key. I run it once and saved the results to `../output/translation.csv` so you could also skip to the cell that has `pd.read_csv(...)` to read it back in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "translations_per_lang = [[] for _ in target_languages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(phrases, target_lang, translations=[], batch_size=100, sleep_sec=1.5): \n",
    "    # big batch sizes might lead to DeadlineExceeded\n",
    "    # sleeping to avoid hitting against the quota (ResourceExhausted error)\n",
    "    num_translated = len(phrases) \n",
    "    for i in tqdm(range(len(translations), num_translated, batch_size), position=0, leave=True):\n",
    "        orig_phrases = phrases[i:i+batch_size]\n",
    "        response = client.translate_text(contents=orig_phrases, target_language_code=target_lang,\n",
    "                                         parent=project, source_language_code='en',\n",
    "                                         model=project + '/locations/global/models/general/nmt')\n",
    "        translated_phrases = [t.translated_text for t in response.translations]\n",
    "        assert len(translated_phrases) == len(orig_phrases)\n",
    "        translations.extend(zip(orig_phrases, translated_phrases))\n",
    "        time.sleep(sleep_sec)\n",
    "    return translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "_ = translate(phrases, target_languages[0], translations_per_lang[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out some dubious phrases to save money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# many of the phrases are not actually English, we can ignore them\n",
    "translations0 = translations_per_lang[0]\n",
    "dubious_phrases = [src for src, dest in translations0 if src.lower() == dest.lower()]\n",
    "true_english_phrases = [src for src, dest in translations0 if src.lower() != dest.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Socio-Med',\n",
       " 'Direct',\n",
       " 'borgyogyaszat',\n",
       " 'Quimica-Bioquimica',\n",
       " 'Adaptat',\n",
       " 'Electrom',\n",
       " 'Landwirtsch',\n",
       " 'Svar',\n",
       " 'Landentwickl',\n",
       " 'WAERME-STOFFUEBERTRAG',\n",
       " 'Enterol',\n",
       " 'Nephrologische',\n",
       " 'Intellig',\n",
       " 'assistenza infermieristica',\n",
       " 'Alergia',\n",
       " 'TURBERK',\n",
       " 'Beob',\n",
       " 'Infektologie',\n",
       " 'Ethno-Natl',\n",
       " 'Irregul']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(dubious_phrases, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Environmental Sciences',\n",
       " 'Methad',\n",
       " 'healthc',\n",
       " 'Period',\n",
       " 'Kinemat',\n",
       " 'coop',\n",
       " 'account',\n",
       " 'Cellular',\n",
       " 'Fin',\n",
       " 'Agronomy',\n",
       " 'PlasticSurgery',\n",
       " 'Facial',\n",
       " 'biochemie',\n",
       " 'ofOtolaryngology/Head',\n",
       " 'Orb',\n",
       " \"d'Electronique\",\n",
       " 'Documents',\n",
       " 'russell-investments',\n",
       " 'Educational',\n",
       " 'PhysicalChemistry']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(true_english_phrases, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7567"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true_english_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "translations_per_lang[0] = [(src, dest) for src, dest in translations0 if src.lower() != dest.lower()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate remaining phrases into remaining languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/44 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating en --> fr\n",
      "Translating en --> es\n",
      "Translating en --> pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [01:18<00:00,  1.79s/it]\n",
      "  0%|          | 0/76 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating en --> ca\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [02:16<00:00,  1.80s/it]\n",
      "  0%|          | 0/76 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating en --> nl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [02:11<00:00,  1.73s/it]\n",
      "  0%|          | 0/76 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating en --> de\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [02:33<00:00,  2.03s/it]\n",
      "  0%|          | 0/76 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating en --> fi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [02:16<00:00,  1.80s/it]\n",
      "  0%|          | 0/76 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating en --> da\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [02:13<00:00,  1.76s/it]\n",
      "  0%|          | 0/76 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating en --> no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [02:14<00:00,  1.77s/it]\n",
      "  0%|          | 0/76 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating en --> tr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [02:11<00:00,  1.73s/it]\n",
      "  0%|          | 0/76 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating en --> hu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [02:16<00:00,  1.80s/it]\n",
      "  0%|          | 0/76 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating en --> pl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [02:13<00:00,  1.76s/it]\n",
      "  0%|          | 0/76 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating en --> el\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [02:37<00:00,  2.08s/it]\n"
     ]
    }
   ],
   "source": [
    "for target_lang, translations in zip(target_languages, translations_per_lang):\n",
    "    print('Translating en --> %s' % target_lang)\n",
    "    translate(true_english_phrases, target_lang, translations)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eye-balling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('andBiological', 'andBiological'),\n",
       " ('Gastroenterology/Hematology', 'Gastroenterology / Hematology'),\n",
       " ('Endocrinolgy', 'Endocrinolgy'),\n",
       " ('Science/Plant', 'Tudomány / Plant'),\n",
       " ('Vigil', 'Virrasztás'),\n",
       " ('Clinical Psychology', 'Klinikai pszichológia'),\n",
       " ('Self-Organiz', 'Self-Organiz'),\n",
       " ('Sport and Exercise Science', 'Sport és testmozgás tudomány'),\n",
       " ('Sport Science', 'Sporttudomány'),\n",
       " ('Gynaecology/', 'Nőgyógyászat/'),\n",
       " ('Antipod', 'Antipod'),\n",
       " ('Most', 'A legtöbb'),\n",
       " ('Crop/Soil', 'Crop / talaj'),\n",
       " ('Neurotraumatology', 'Neurotraumatology'),\n",
       " ('Disc', 'Lemez'),\n",
       " ('Non-West', 'Non-West'),\n",
       " ('Syntax-Semant', 'Syntax-Semant'),\n",
       " ('Drug-Facil', 'Kábítószer-Facil'),\n",
       " ('Histocompatibility', 'hisztokompatibilitási'),\n",
       " ('medycyna laboratoryjna', 'medycyna laboratórium')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(random.choice(translations_per_lang), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SurgeryK', 'Chirurgia'),\n",
       " ('Multitask', 'Wielozadaniowy'),\n",
       " ('Machinery', 'Maszyneria'),\n",
       " ('opencounter', 'OpenCounter'),\n",
       " ('Hydrobiology', 'Hydrobiologia'),\n",
       " ('Fright', 'Strach'),\n",
       " ('Ambassad', 'Ambasador'),\n",
       " ('Aqueous-Org', 'Org. Wodny'),\n",
       " ('Low-Temp', 'Niska temperatura'),\n",
       " ('Psychotherapy', 'Psychoterapia'),\n",
       " ('Tenn', 'Tenn'),\n",
       " ('computer-packages-inc', 'computer-Package-inc'),\n",
       " ('Foster', 'Sprzyjać'),\n",
       " ('Echography', 'Echografia'),\n",
       " (\"d'Obstetricia\", 'd&#39;Obstetricia'),\n",
       " ('State-Corp', 'State-Corp'),\n",
       " ('Cardiac Electrophysiology', 'Elektrofizjologia serca'),\n",
       " ('Cases', 'Skrzynie'),\n",
       " ('Inorganic', 'Nieorganiczny'),\n",
       " ('German-Dan', 'Niemiecki-Dan')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(random.choice(translations_per_lang), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Molecular Toxicology', 'Toxicología Molecular'),\n",
       " ('endokrynologia', 'endocrinologia'),\n",
       " ('Hematology/G03.647', 'Hematología / G03.647'),\n",
       " ('Medical Education', 'Educación médica'),\n",
       " ('autogrid-systems', 'sistemas de autogrid'),\n",
       " ('Community', 'Comunidad'),\n",
       " ('Economy', 'Economía'),\n",
       " ('Herbic', 'Herbic'),\n",
       " ('legal-science-partners', 'socios de ciencias jurídicas'),\n",
       " ('Animal Science', 'Ciencia Animal'),\n",
       " ('Padova/Math', 'Padua / Matemáticas'),\n",
       " ('Pestic', 'Pesticida'),\n",
       " ('Med./Radiology', 'Med./Radiology'),\n",
       " ('Rheum', 'Reuma'),\n",
       " ('medical oncology', 'Oncologia medica'),\n",
       " ('Stem Cell and Regenerative Medicine',\n",
       "  'Células Madre y Medicina Regenerativa'),\n",
       " ('Amazon', 'Amazonas'),\n",
       " ('Midwifery', 'Partería'),\n",
       " ('Stem Cells', 'Células madre'),\n",
       " ('Cell Signaling', 'Señal telefónica')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(random.choice(translations_per_lang), 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_translations = list(zip(target_languages, translations_per_lang))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../output/translations.json', 'w') as f:\n",
    "    json.dump(all_translations, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[\"fr\", [[\"Marine\", \"Marin\"], [\"Radiation Therapy\", \"Radioth\\u00e9rapie\"], [\"Immunology\", \"Immunologie\"], [\"Gastroenterol.and\", \"Gastroenterol.et\"], [\"HPV-Relat\", \"Relation HPV\"], [\"Bioengineering\", \"Bioing\\u00e9nierie\"], [\"ofPoly\", \"dePoly\"], [\"Four-Vol\", \"Quatre-vol\"], [\"d'Hgmatologie\", \"d&#39;Hgmatologie\"], [\"Mange\", \"Gale\"], [\"Remodel\", \"Remodeler\"], [\"Approac\", \"Approche\"], [\"Immunology-IMM18\", \"Immunologie-IMM18\"], [\"Peruv\", \"P\\u00e9ruv\"], [\"Chinese Pharmaceutics\", \"Pharmacie chinoise\"], [\"Iberoam\", \"Ib\\u00e9ro\"], [\"nationwide-mutual-insurance-company\", \"compagnie d&#39;assurance mutuelle nationale\"], [\"process\", \"processus\"], [\"Manufacture\", \"Fabrication\"], [\"Truth-Tell\", \"V\\u00e9rit\\u00e9 dire\"], [\"Modern Textile\", \"Textile moderne\"], [\"Chest Diseases\", \"Maladies de la poitrine\"], [\"Aware\", \"Conscient\"], [\"Mat\", \"Tapis\"], [\"subst\", \"sous-marin\"], [\"Dairy-Deriv\", \"Produits laitiers d\\u00e9riv\\u00e9s\"], [\"Nutritional Sciences\", \"Sciences de la nutrition\"], [\"Hearing\", \"Audition\"], [\"Health Administration\", \"Administration de sant\\u00e9\"], [\"renew\", \"renouveler\"], [\"Translational Medicine\", \"M\\u00e9decine translationnelle\"], [\"Prime-Detect\", \"Premier D\\u00e9tecter\"], [\"import\", \"importation\"], [\"FoodTechnology\", \"Technologie alimentaire\"], [\"Expens\", \"Frais\"], [\"Gene Regulation\", \"R\\u00e9gulation G\\u00e9nique\"], [\"High-perform\", \"Performant\"], [\"Reserv\", \"R\\u00e9serve\"], [\"EngineeringPhysics\", \"Physiques de l&#39;ingenieur\"], [\"Onco-Hematology\", \"Onco-H\\u00e9matologie\"], [\"andAgricultural\", \"etagricole\"], [\"Age-Different\", \"Diff\\u00e9rence d&#39;\\u00e2ge\"], [\"Applied Microbiology\", \"Microbiologie appliqu\\u00e9e\"], [\"Mech./Engineering\", \"Mech./Ing\\u00e9nierie\"], [\"48-factoring-inc\", \"48-affacturage-inc\"], [\"medicina pediatrica de cuidados criticos\", \"medicina pediatrica de cuidados critiques\"], [\"Gastrenterol\", \"Gastrent\\u00e9rol\"], [\"Cathar\", \"Cathare\"], [\"Reproductive\", \"Reproducteur\"], [\"Storytell\", \"Conte\"], [\"Electron Microscopy\", \"Microscopie \\u00e9lectron"
     ]
    }
   ],
   "source": [
    "!head -c 2000 ../output/translations.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate word lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../output/translations.json') as f:\n",
    "    all_translations = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target_lang, translations in all_translations:\n",
    "    dictionary = dict(translations)\n",
    "    for src_path in wordlist_paths:\n",
    "        dest_path = src_path.replace('.txt', '.%s.txt' % target_lang)\n",
    "        with open(src_path) as f:\n",
    "            phrases = [p.strip() for p in f]\n",
    "        translated_phrases = [dictionary[p] for p in phrases if p in dictionary]\n",
    "        with open(dest_path, 'w') as f:\n",
    "            for p in translated_phrases:\n",
    "                f.write(p)\n",
    "                f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   49457 dicts/acronym_whitelist.txt\n",
      "   81257 dicts/allLocDict.txt\n",
      "      18 dicts/blackListDict.txt\n",
      "      21 dicts/commonSubjectsDict.ca.txt\n",
      "      21 dicts/commonSubjectsDict.da.txt\n",
      "      21 dicts/commonSubjectsDict.de.txt\n",
      "      21 dicts/commonSubjectsDict.el.txt\n",
      "      21 dicts/commonSubjectsDict.es.txt\n",
      "      21 dicts/commonSubjectsDict.fi.txt\n",
      "      21 dicts/commonSubjectsDict.fr.txt\n",
      "      21 dicts/commonSubjectsDict.hu.txt\n",
      "      21 dicts/commonSubjectsDict.nl.txt\n",
      "      21 dicts/commonSubjectsDict.no.txt\n",
      "      21 dicts/commonSubjectsDict.pl.txt\n",
      "      21 dicts/commonSubjectsDict.pt.txt\n",
      "      21 dicts/commonSubjectsDict.tr.txt\n",
      "      23 dicts/commonSubjectsDict.txt\n",
      "     253 dicts/companyNames.ca.txt\n",
      "     253 dicts/companyNames.da.txt\n",
      "     253 dicts/companyNames.de.txt\n",
      "     253 dicts/companyNames.el.txt\n",
      "     253 dicts/companyNames.es.txt\n",
      "     253 dicts/companyNames.fi.txt\n",
      "     253 dicts/companyNames.fr.txt\n",
      "     253 dicts/companyNames.hu.txt\n",
      "     253 dicts/companyNames.nl.txt\n",
      "     253 dicts/companyNames.no.txt\n",
      "     253 dicts/companyNames.pl.txt\n",
      "     253 dicts/companyNames.pt.txt\n",
      "     253 dicts/companyNames.tr.txt\n",
      "     543 dicts/companyNames.txt\n",
      "       9 dicts/companySuffixes.ca.txt\n",
      "       9 dicts/companySuffixes.da.txt\n",
      "       9 dicts/companySuffixes.de.txt\n",
      "       9 dicts/companySuffixes.el.txt\n",
      "       9 dicts/companySuffixes.es.txt\n",
      "       9 dicts/companySuffixes.fi.txt\n",
      "       9 dicts/companySuffixes.fr.txt\n",
      "       9 dicts/companySuffixes.hu.txt\n",
      "       9 dicts/companySuffixes.nl.txt\n",
      "       9 dicts/companySuffixes.no.txt\n",
      "       9 dicts/companySuffixes.pl.txt\n",
      "       9 dicts/companySuffixes.pt.txt\n",
      "       9 dicts/companySuffixes.tr.txt\n",
      "       9 dicts/companySuffixes.txt\n",
      "       7 dicts/companyTypes.ca.txt\n",
      "       7 dicts/companyTypes.da.txt\n",
      "       7 dicts/companyTypes.de.txt\n",
      "       7 dicts/companyTypes.el.txt\n",
      "       7 dicts/companyTypes.es.txt\n",
      "       7 dicts/companyTypes.fi.txt\n",
      "       7 dicts/companyTypes.fr.txt\n",
      "       7 dicts/companyTypes.hu.txt\n",
      "       7 dicts/companyTypes.nl.txt\n",
      "       7 dicts/companyTypes.no.txt\n",
      "       7 dicts/companyTypes.pl.txt\n",
      "       7 dicts/companyTypes.pt.txt\n",
      "       7 dicts/companyTypes.tr.txt\n",
      "      24 dicts/companyTypes.txt\n",
      "       2 dicts/connectorsDict.ca.txt\n",
      "       2 dicts/connectorsDict.da.txt\n",
      "       2 dicts/connectorsDict.de.txt\n",
      "       2 dicts/connectorsDict.el.txt\n",
      "       2 dicts/connectorsDict.es.txt\n",
      "       2 dicts/connectorsDict.fi.txt\n",
      "       2 dicts/connectorsDict.fr.txt\n",
      "       2 dicts/connectorsDict.hu.txt\n",
      "       2 dicts/connectorsDict.nl.txt\n",
      "       2 dicts/connectorsDict.no.txt\n",
      "       2 dicts/connectorsDict.pl.txt\n",
      "       2 dicts/connectorsDict.pt.txt\n",
      "       2 dicts/connectorsDict.tr.txt\n",
      "       5 dicts/connectorsDict.txt\n",
      "       8 dicts/orgModifiersDict.ca.txt\n",
      "       8 dicts/orgModifiersDict.da.txt\n",
      "       8 dicts/orgModifiersDict.de.txt\n",
      "       8 dicts/orgModifiersDict.el.txt\n",
      "       8 dicts/orgModifiersDict.es.txt\n",
      "       8 dicts/orgModifiersDict.fi.txt\n",
      "       8 dicts/orgModifiersDict.fr.txt\n",
      "       8 dicts/orgModifiersDict.hu.txt\n",
      "       8 dicts/orgModifiersDict.nl.txt\n",
      "       8 dicts/orgModifiersDict.no.txt\n",
      "       8 dicts/orgModifiersDict.pl.txt\n",
      "       8 dicts/orgModifiersDict.pt.txt\n",
      "       8 dicts/orgModifiersDict.tr.txt\n",
      "       9 dicts/orgModifiersDict.txt\n",
      "     304 dicts/subjectModifiersDict.ca.txt\n",
      "     304 dicts/subjectModifiersDict.da.txt\n",
      "     304 dicts/subjectModifiersDict.de.txt\n",
      "     304 dicts/subjectModifiersDict.el.txt\n",
      "     304 dicts/subjectModifiersDict.es.txt\n",
      "     304 dicts/subjectModifiersDict.fi.txt\n",
      "     304 dicts/subjectModifiersDict.fr.txt\n",
      "     304 dicts/subjectModifiersDict.hu.txt\n",
      "     304 dicts/subjectModifiersDict.nl.txt\n",
      "     304 dicts/subjectModifiersDict.no.txt\n",
      "     304 dicts/subjectModifiersDict.pl.txt\n",
      "     304 dicts/subjectModifiersDict.pt.txt\n",
      "     304 dicts/subjectModifiersDict.tr.txt\n",
      "     342 dicts/subjectModifiersDict.txt\n",
      "    5938 dicts/subjectsDict-new.ca.txt\n",
      "    5938 dicts/subjectsDict-new.da.txt\n",
      "    5938 dicts/subjectsDict-new.de.txt\n",
      "    5938 dicts/subjectsDict-new.el.txt\n",
      "    5938 dicts/subjectsDict-new.es.txt\n",
      "    5938 dicts/subjectsDict-new.fi.txt\n",
      "    5938 dicts/subjectsDict-new.fr.txt\n",
      "    5938 dicts/subjectsDict-new.hu.txt\n",
      "    5938 dicts/subjectsDict-new.nl.txt\n",
      "    5938 dicts/subjectsDict-new.no.txt\n",
      "    5938 dicts/subjectsDict-new.pl.txt\n",
      "    5938 dicts/subjectsDict-new.pt.txt\n",
      "    5938 dicts/subjectsDict-new.tr.txt\n",
      "   15521 dicts/subjectsDict-new.txt\n",
      "    1483 dicts/subjectsDict.ca.txt\n",
      "    1483 dicts/subjectsDict.da.txt\n",
      "    1483 dicts/subjectsDict.de.txt\n",
      "    1483 dicts/subjectsDict.el.txt\n",
      "    1483 dicts/subjectsDict.es.txt\n",
      "    1483 dicts/subjectsDict.fi.txt\n",
      "    1483 dicts/subjectsDict.fr.txt\n",
      "    1483 dicts/subjectsDict.hu.txt\n",
      "    1483 dicts/subjectsDict.nl.txt\n",
      "    1483 dicts/subjectsDict.no.txt\n",
      "    1483 dicts/subjectsDict.pl.txt\n",
      "    1483 dicts/subjectsDict.pt.txt\n",
      "    1483 dicts/subjectsDict.tr.txt\n",
      "    1705 dicts/subjectsDict.txt\n",
      "    2336 dicts/sw_dict.txt\n",
      "      59 dicts/typesDict.ca.txt\n",
      "      59 dicts/typesDict.da.txt\n",
      "      59 dicts/typesDict.de.txt\n",
      "      59 dicts/typesDict.el.txt\n",
      "      59 dicts/typesDict.es.txt\n",
      "      59 dicts/typesDict.fi.txt\n",
      "      59 dicts/typesDict.fr.txt\n",
      "      59 dicts/typesDict.hu.txt\n",
      "      59 dicts/typesDict.nl.txt\n",
      "      59 dicts/typesDict.no.txt\n",
      "      59 dicts/typesDict.pl.txt\n",
      "      59 dicts/typesDict.pt.txt\n",
      "      59 dicts/typesDict.tr.txt\n",
      "     120 dicts/typesDict.txt\n",
      "       6 dicts/univKeywords.ca.txt\n",
      "       6 dicts/univKeywords.da.txt\n",
      "       6 dicts/univKeywords.de.txt\n",
      "       6 dicts/univKeywords.el.txt\n",
      "       6 dicts/univKeywords.es.txt\n",
      "       6 dicts/univKeywords.fi.txt\n",
      "       6 dicts/univKeywords.fr.txt\n",
      "       6 dicts/univKeywords.hu.txt\n",
      "       6 dicts/univKeywords.nl.txt\n",
      "       6 dicts/univKeywords.no.txt\n",
      "       6 dicts/univKeywords.pl.txt\n",
      "       6 dicts/univKeywords.pt.txt\n",
      "       6 dicts/univKeywords.tr.txt\n",
      "      30 dicts/univKeywords.txt\n",
      "      15 dicts/whiteListDict.txt\n",
      "      16 dicts/wordEndingsDict.ca.txt\n",
      "      16 dicts/wordEndingsDict.da.txt\n",
      "      16 dicts/wordEndingsDict.de.txt\n",
      "      16 dicts/wordEndingsDict.el.txt\n",
      "      16 dicts/wordEndingsDict.es.txt\n",
      "      16 dicts/wordEndingsDict.fi.txt\n",
      "      16 dicts/wordEndingsDict.fr.txt\n",
      "      16 dicts/wordEndingsDict.hu.txt\n",
      "      16 dicts/wordEndingsDict.nl.txt\n",
      "      16 dicts/wordEndingsDict.no.txt\n",
      "      16 dicts/wordEndingsDict.pl.txt\n",
      "      16 dicts/wordEndingsDict.pt.txt\n",
      "      16 dicts/wordEndingsDict.tr.txt\n",
      "      79 dicts/wordEndingsDict.txt\n",
      "  256871 total\n"
     ]
    }
   ],
   "source": [
    "!wc -l dicts/*.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:generic-classifier] *",
   "language": "python",
   "name": "conda-env-generic-classifier-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
